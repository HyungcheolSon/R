install.packages("wordcloud")
 
# 패키지 로드
library(wordcloud)
library(RColorBrewer)
 
pal <- brewer.pal(8,"Dark2")  # Dark2 색상 목록에서 8개 색상 추출
 
wordcloud(words = df_word$word,  # 단어
          freq = df_word$freq,   # 빈도
          min.freq = 2,          # 최소 단어 빈도
          max.words = 200,       # 표현 단어 수
          random.order = F,      # 고빈도 단어 중앙 배치
          rot.per = .1,          # 회전 단어 비율
          scale = c(4, 0.3),     # 단어 크기 범위
          colors = pal)          # 색깔 목록






7) 단어색상 바꾸기
- 파란색 계열의 색상 목록을 만들어 빈도가 높을수록 진한 파란색으로 표현한다.
pal <- brewer.pal(9,"Blues")[5:9]  # 색상 목록 생성
 
wordcloud(words = df_word$word,    # 단어
          freq = df_word$freq,     # 빈도
          min.freq = 2,            # 최소 단어 빈도
          max.words = 200,         # 표현 단어 수
          random.order = F,        # 고빈도 단어 중앙 배치
          rot.per = .1,            # 회전 단어 비율
          scale = c(4, 0.3),       # 단어 크기 범위
          colors = pal)            # 색상 목록
 








(2) 국정원 트윗 텍스트 마이닝  
- 텍스트 마이닝은 소셜네트워크에 올라온 글을 통해 사람들의 생각들을 확인 할때 많이 사용되어진다.
- 국정원 계정의 트윗 3,744개의 데이터를 이용한다.

1) 데이터 준비
- twitter.csv파일을 프로젝트 폴더에 넣는다.
- 한글변수명을 다루기 쉽게 영어이름으로 변경하고 특수문자 제거한다.

# 데이터 로드
twitter <- read.csv("twitter.csv",
                    header = T,
                    stringsAsFactors = F,
                    fileEncoding = "UTF-8")
 
# 변수명 수정
twitter <- rename(twitter,
                  no = 번호,
                  id = 계정이름,
                  date = 작성일,
                  tw = 내용)
 
# 특수문자 제거
twitter$tw <- str_replace_all(twitter$tw, "\\W", " ")
 
> head(twitter$tw)
[1] "민주당의 ISD관련 주장이 전부 거짓으로 속속 드러나고있다  미국이 ISD를 장악하고 있다고 주장하지만 중재인 123명 가운데 미국인은 10명뿐이라고 한다 "                                                                               
[2] "말로만  미제타도   사실은  미제환장   김정일 운구차가 링컨 컨티넬탈이던데 북한의 독재자나 우리나라 종북들이나 겉으로는 노동자  서민을 대변한다면서 고급 외제차  아이팟에 자식들 미국 유학에 환장하는 위선자들인거죠"            
[3] "한나라당이 보수를 버린다네요 뭔가착각하는모냥인에 국민들이보수를싫어하는게 아니라뻘짓거리하는분들을싫어하는겁니다야당이진보어쩌고저쩌고한다고해서그들을조아한다고생각하면대착각"                                                
[4] "FTA를 대하는 현명한 자세  사실 자유주의 경제의 가장 큰 수해자는 한국이죠  농어업분야 피해를 줄이는 정부대안을 최대한  보완하고 일자리 창출 등 실익을 최대화해 나가는게 현실적인 대처자세일듯 "                                  
[5] "곽노현씨 갈수록 가관입니다  뇌물질에 아들 병역 의혹까지  도대체 아이들이 뮐 보고 배우겠습니까  이래도 자리 연연하시겠습니까 "                                                                                                   
[6] "과거 집권시 한미FTA를 적극 추진하던 세력이 이제 집권하면 폐기하겠다고 주장합니다  어이없어 말도 안 나오네요  표만 얻을 수 있다면 국가 안보나 경제가 어떻게 되든 상관없다는 무책임한 행태들  우리 정치의 후진성을 드러내는 거죠 "
 


2) 단어 빈도표 생성 
- 트윗에서 명사 추출후, 각 단어가 몇 번씩 사용됐는지 나타낸 빈도표를 만든다.
- 두 글자 이상된 단어 추출후 빈도순으로 정렬하여 상위20객 추출한다

# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)
 
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
 
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
 
# 변수명 수정
df_word <- rename(df_word,
                  word = Var1,
                  freq = Freq)
 
 
# 두 글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
 
# 상위 20개 추출
top20 <- df_word %>%
  arrange(desc(freq)) %>%
  head(20)

> top20
       word freq
1      북한 2216
2  대한민국  804
3      우리  779
4      좌파  641
5      국민  550
6      들이  428
7      세력  409
8      친북  385
9    김정일  342
10     단체  335
11     진보  333
12     대선  329
13   천안함  319
14     사회  307
15     정부  283
16   전교조  278
17     주장  269
18     정권  263
19   연평도  262
20     국가  242

3) 단어 빈도 막대그래프 생성
- ggplot2를 이용하여 막대 그래프 만든다.

library(ggplot2)
 
order <- arrange(top20, freq)$word               # 빈도 순서 변수 생성
 
ggplot(data = top20, aes(x = word, y = freq)) +  
  ylim(0, 2500) +
  geom_col() + 
  coord_flip() +
  scale_x_discrete(limit = order) +              # 빈도 순서 변수 기준 막대 정렬
  geom_text(aes(label = freq), hjust = -0.3)     # 빈도 표시

 


4) 워드 클라우드 생성

pal <- brewer.pal(8,"Dark2")       # 색상 목록 생성
 
wordcloud(words = df_word$word,    # 단어
          freq = df_word$freq,     # 빈도
          min.freq = 10,           # 최소 단어 빈도
          max.words = 200,         # 표현 단어 수
          random.order = F,        # 고빈도 단어 중앙 배치
          rot.per = .1,            # 회전 단어 비율
          scale = c(6, 0.2),       # 단어 크기 범위
          colors = pal)            # 색상 목록
 


- 단어 색상을 파란계열로 바꿔 워드 클라우드 생성

pal <- brewer.pal(9,"Blues")[5:9]  # 색상 목록 생성
 
wordcloud(words = df_word$word,    # 단어
          freq = df_word$freq,     # 빈도
          min.freq = 10,           # 최소 단어 빈도
          max.words = 200,         # 표현 단어 수
          random.order = F,        # 고빈도 단어 중앙 배치
          rot.per = .1,            # 회전 단어 비율
          scale = c(6, 0.2),       # 단어 크기 범위
          colors = pal)            # 색상 목록
 

  ※ wordcloud함수 설명
        wordcloud(words = df_word$word,    # 단어
                   freq = df_word$freq,        # 빈도
                   min.freq = 10,                # 최소 단어 빈도
                   max.words = 200,           # 표현 단어 수
                   random.order = F,          # 고빈도 단어 중앙 배치
                   rot.per = .1,                  # 회전 단어 비율
                   scale = c(6, 0.2),            # 단어 크기 범위
                   colors = pal) 

 
 words 수만큼 freq (빈도)를 나타낸다.
 등장하는 단어의 가장 작은 빈도 수는10로,
 등장하는 단어의 가장 큰 빈도 수는 200이다.
 빈도가 가장 큰 단어를 중앙에 두도록 하기 위해 random order는 False 값을 준다.
 scale(폰트의 크기)은 최고 6픽셀에서, 제일 작은건 0.2 픽셀까지
 rotation되는 단어의 빈도는 0.1정도로 하고, 
 컬러는 위에서 정한 pal의 값으로 컬러 팔레트를 사용한다. 



top_10<-arrange(top_10,word,freq)
top_10_1<-ddply(top_10,"word",transform,누적합계=cumsum(freq))
top_10_2<-ddply(top_10_1,"word",transform,누적합계=cumsum(freq),label=cumsum(freq)-0.5*freq)
top_10_2
ggplot(top_10_2, aes(x=word,y=freq))+geom_bar(stat="identity")+geom_text(aes(y=label,label=paste(freq,'번')),color="white",size=3) <=내가 만든 코드